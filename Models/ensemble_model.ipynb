{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a44d2e05",
      "metadata": {},
      "source": [
        "Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecb1ddc8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# imports\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98a9a033",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df = pd.read_csv('train.csv')\n",
        "df_raw = pd.read_csv('train.csv')\n",
        "\n",
        "# drop unnecessary columns\n",
        "df = df.drop(columns=['weather_temperature', 'weather_wind_mph', 'weather_humidity', 'weather_detail', 'stadium'])\n",
        "df.head()\n",
        "\n",
        "# adding total score columns\n",
        "df['total_score'] = df['score_home'] + df['score_away']\n",
        "\n",
        "\n",
        "# add column that represented current record for each team before each game of a season\n",
        "# ensure games are sorted chronologically within each season\n",
        "df[\"datetime\"] = pd.to_datetime(df[\"schedule_date\"])\n",
        "df = df.sort_values([\"schedule_season\", \"datetime\"]).reset_index(drop=True)\n",
        "\n",
        "# make output lists\n",
        "home_records = []\n",
        "away_records = []\n",
        "\n",
        "# make dictionaries to track each team's W-L-T within the current season\n",
        "team_wins = {}\n",
        "team_losses = {}\n",
        "team_ties = {}\n",
        "\n",
        "current_season = None\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    season = row[\"schedule_season\"]\n",
        "    home = row[\"team_home\"]\n",
        "    away = row[\"team_away\"]\n",
        "    home_score = row[\"score_home\"]\n",
        "    away_score = row[\"score_away\"]\n",
        "   \n",
        "    # new season,  reset all\n",
        "    if season != current_season:\n",
        "        team_wins = {}\n",
        "        team_losses = {}\n",
        "        team_ties = {}\n",
        "        current_season = season\n",
        "\n",
        "    # initialize teams for this season if needed\n",
        "    for team in [home, away]:\n",
        "        if team not in team_wins:\n",
        "            team_wins[team] = 0\n",
        "            team_losses[team] = 0\n",
        "            team_ties[team] = 0\n",
        "\n",
        "    # add current record before the game\n",
        "    home_records.append(\n",
        "        f\"{team_wins[home]}-{team_losses[home]}-{team_ties[home]}\"\n",
        "    )\n",
        "    away_records.append(\n",
        "        f\"{team_wins[away]}-{team_losses[away]}-{team_ties[away]}\"\n",
        "    )\n",
        "\n",
        "    # update records after the game\n",
        "    if home_score > away_score:\n",
        "        team_wins[home] += 1\n",
        "        team_losses[away] += 1\n",
        "    elif away_score > home_score:\n",
        "        team_wins[away] += 1\n",
        "        team_losses[home] += 1\n",
        "    else:\n",
        "        # tie\n",
        "        team_ties[home] += 1\n",
        "        team_ties[away] += 1\n",
        "\n",
        "# add results to dataframe\n",
        "df[\"home_team_record\"] = home_records\n",
        "df[\"away_team_record\"] = away_records\n",
        "\n",
        "\n",
        "# make individual columns for wins, losses, and ties\n",
        "df['home_wins'] = df['home_team_record'].apply(lambda x: int(x.split('-')[0]))\n",
        "df['home_losses'] = df['home_team_record'].apply(lambda x: int(x.split('-')[1]))\n",
        "df['home_ties'] = df['home_team_record'].apply(lambda x: int(x.split('-')[2]))\n",
        "df['away_wins'] = df['away_team_record'].apply(lambda x: int(x.split('-')[0]))\n",
        "df['away_losses'] = df['away_team_record'].apply(lambda x: int(x.split('-')[1]))\n",
        "df['away_ties'] = df['away_team_record'].apply(lambda x: int(x.split('-')[2]))\n",
        "\n",
        "\n",
        "# filter games that have already been recorded, no scheduled games\n",
        "df = df[df[\"datetime\"] <= \"2025-11-04\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ccc67f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute each team's average score per season\n",
        "team_season_avg = (\n",
        "    df.groupby([\"team_home\", \"schedule_season\"])[\"score_home\"].mean().reset_index()\n",
        ")\n",
        "team_season_avg.columns = [\"team\", \"season\", \"avg_score\"]\n",
        "\n",
        "# also include away team scoring\n",
        "team_season_avg_away = (\n",
        "    df.groupby([\"team_away\", \"schedule_season\"])[\"score_away\"].mean().reset_index()\n",
        ")\n",
        "team_season_avg_away.columns = [\"team\", \"season\", \"avg_score\"]\n",
        "\n",
        "# combine home + away scoring for a true team season average\n",
        "team_season_avg = pd.concat([team_season_avg, team_season_avg_away])\n",
        "team_season_avg = team_season_avg.groupby([\"team\", \"season\"])[\"avg_score\"].mean().reset_index()\n",
        "\n",
        "# shift averages to represent previous season\n",
        "team_season_avg[\"prev_season\"] = team_season_avg[\"season\"] + 1\n",
        "\n",
        "# prev_season avg is used in the next year's games\n",
        "team_prev = team_season_avg[[\"team\", \"prev_season\", \"avg_score\"]]\n",
        "team_prev.columns = [\"team\", \"schedule_season\", \"prev_season_avg\"]\n",
        "\n",
        "# merge into main df\n",
        "df = df.merge(team_prev, left_on=[\"team_home\", \"schedule_season\"], right_on=[\"team\", \"schedule_season\"], how=\"left\")\n",
        "df.rename(columns={\"prev_season_avg\": \"home_prev_avg\"}, inplace=True)\n",
        "df = df.drop(columns=[\"team\"])\n",
        "\n",
        "df = df.merge(team_prev, left_on=[\"team_away\", \"schedule_season\"], right_on=[\"team\", \"schedule_season\"], how=\"left\")\n",
        "df.rename(columns={\"prev_season_avg\": \"away_prev_avg\"}, inplace=True)\n",
        "df = df.drop(columns=[\"team\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ba8a6b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating rolling avgs within each season\n",
        "\n",
        "# separate into home, away dfs\n",
        "home = df[[\"schedule_season\", \"datetime\", \"team_home\", \"score_home\", \"score_away\"]].rename(\n",
        "    columns={\"team_home\": \"team\", \"score_home\": \"points_scored\", \"score_away\": \"points_allowed\"}\n",
        ")\n",
        "\n",
        "away = df[[\"schedule_season\", \"datetime\", \"team_away\", \"score_away\", \"score_home\"]].rename(\n",
        "    columns={\"team_away\": \"team\", \"score_away\": \"points_scored\", \"score_home\": \"points_allowed\"}\n",
        ")\n",
        "\n",
        "# long df, duplicate games, sort by team, season, date\n",
        "long_df = pd.concat([home, away])\n",
        "long_df = long_df.sort_values([\"team\", \"schedule_season\", \"datetime\"]).reset_index(drop=True)\n",
        "\n",
        "groups = long_df.groupby([\"team\", \"schedule_season\"])\n",
        "\n",
        "# compute rolling averages\n",
        "long_df[\"rolling_scored\"] = groups[\"points_scored\"].transform(\n",
        "    lambda s: s.shift().expanding().mean()\n",
        ")\n",
        "\n",
        "long_df[\"rolling_allowed\"] = groups[\"points_allowed\"].transform(\n",
        "    lambda s: s.shift().expanding().mean()\n",
        ")\n",
        "\n",
        "# merge back into original df\n",
        "df = df.merge(\n",
        "    long_df[[\"team\", \"schedule_season\", \"datetime\", \"rolling_scored\", \"rolling_allowed\"]],\n",
        "    left_on=[\"team_home\", \"schedule_season\", \"datetime\"],\n",
        "    right_on=[\"team\", \"schedule_season\", \"datetime\"],\n",
        "    how=\"left\"\n",
        ").rename(\n",
        "    columns={\n",
        "        \"rolling_scored\": \"home_rolling_scored\",\n",
        "        \"rolling_allowed\": \"home_rolling_allowed\"\n",
        "    }\n",
        ").drop(columns=[\"team\"])\n",
        "\n",
        "\n",
        "df = df.merge(\n",
        "    long_df[[\"team\", \"schedule_season\", \"datetime\", \"rolling_scored\", \"rolling_allowed\"]],\n",
        "    left_on=[\"team_away\", \"schedule_season\", \"datetime\"],\n",
        "    right_on=[\"team\", \"schedule_season\", \"datetime\"],\n",
        "    how=\"left\"\n",
        ").rename(\n",
        "    columns={\n",
        "        \"rolling_scored\": \"away_rolling_scored\",\n",
        "        \"rolling_allowed\": \"away_rolling_allowed\"\n",
        "    }\n",
        ").drop(columns=[\"team\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2613b9df",
      "metadata": {},
      "source": [
        "### Ensemble Model (Gradient Boosting)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1c8ddf6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# imports\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae0d85f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dropping variables that aren't informative to our model\n",
        "df_filtered = df.drop(columns=['datetime', 'stadium_neutral', 'home_team_record', 'away_team_record',\n",
        "                       'schedule_date', 'team_favorite_id', 'team_home', 'team_away', 'schedule_week'])\n",
        "df_filtered = df_filtered.dropna(axis = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69a5a1a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# splitting into x and y\n",
        "X = df_filtered.drop(columns=['total_score', 'over_under_line', 'score_home', 'score_away'])\n",
        "y = df_filtered['total_score']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5362c024",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 123)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f597625",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify categorical + numeric columns\n",
        "categorical_cols = ['schedule_playoff']\n",
        "numeric_cols = [col for col in X_train.columns if col not in categorical_cols]\n",
        "\n",
        "# Column transformer to handle preprocessing\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='if_binary'), categorical_cols),\n",
        "        ('num', StandardScaler(), numeric_cols)])\n",
        "\n",
        "# Build preprocess, Gradient Boosting pipeline\n",
        "pip = Pipeline(steps=[('preprocess', preprocess),('gbr', GradientBoostingRegressor(random_state=123))])\n",
        "\n",
        "# Parameter grid for Gradient Boosting\n",
        "param_grid = {\n",
        "    'gbr__n_estimators': [50, 100, 200],\n",
        "    'gbr__learning_rate': [0.01, 0.1, 0.2],\n",
        "    'gbr__max_depth': [3, 5, 7],\n",
        "    'gbr__min_samples_split': [2, 5, 10],\n",
        "    'gbr__min_samples_leaf': [1, 2, 4],\n",
        "    'gbr__subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "grid_search = GridSearchCV(pip, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
        "\n",
        "# Fit on raw X_train and y_train\n",
        "grid_search.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fadefa39",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Results\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best CV MSE:\", round(-grid_search.best_score_,3))\n",
        "print(\"Best CV RMSE:\", round(np.sqrt(-grid_search.best_score_),3))\n",
        "\n",
        "best_gbr = grid_search.best_estimator_\n",
        "y_pred = best_gbr.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "print(\"Test RÂ²:\", round(r2_score(y_test, y_pred),3))\n",
        "print(\"Test MSE:\", round(mean_squared_error(y_test, y_pred),3))\n",
        "print(\"Test RMSE:\", round(np.sqrt(mean_squared_error(y_test, y_pred)),3))\n",
        "print(\"Test MAE:\", round(mean_absolute_error(y_test, y_pred), 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d8cc69f",
      "metadata": {},
      "source": [
        "The Gradient Boosting Regressor model results should be evaluated against the SVR model to determine which performs better for predicting total scores.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
