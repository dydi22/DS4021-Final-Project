{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "df_raw = pd.read_csv('train.csv')\n",
    "\n",
    "# drop unnecessary columns\n",
    "df = df.drop(columns=['weather_temperature', 'weather_wind_mph', 'weather_humidity', 'weather_detail', 'stadium'])\n",
    "df.head()\n",
    "\n",
    "# adding total score columns\n",
    "df['total_score'] = df['score_home'] + df['score_away']\n",
    "\n",
    "\n",
    "# add column that represented current record for each team before each game of a season\n",
    "# ensure games are sorted chronologically within each season\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"schedule_date\"])\n",
    "df = df.sort_values([\"schedule_season\", \"datetime\"]).reset_index(drop=True)\n",
    "\n",
    "# make output lists\n",
    "home_records = []\n",
    "away_records = []\n",
    "\n",
    "# make dictionaries to track each team's W-L-T within the current season\n",
    "team_wins = {}\n",
    "team_losses = {}\n",
    "team_ties = {}\n",
    "\n",
    "current_season = None\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    season = row[\"schedule_season\"]\n",
    "    home = row[\"team_home\"]\n",
    "    away = row[\"team_away\"]\n",
    "    home_score = row[\"score_home\"]\n",
    "    away_score = row[\"score_away\"]\n",
    "   \n",
    "    # new season,  reset all\n",
    "    if season != current_season:\n",
    "        team_wins = {}\n",
    "        team_losses = {}\n",
    "        team_ties = {}\n",
    "        current_season = season\n",
    "\n",
    "    # initialize teams for this season if needed\n",
    "    for team in [home, away]:\n",
    "        if team not in team_wins:\n",
    "            team_wins[team] = 0\n",
    "            team_losses[team] = 0\n",
    "            team_ties[team] = 0\n",
    "\n",
    "    # add current record before the game\n",
    "    home_records.append(\n",
    "        f\"{team_wins[home]}-{team_losses[home]}-{team_ties[home]}\"\n",
    "    )\n",
    "    away_records.append(\n",
    "        f\"{team_wins[away]}-{team_losses[away]}-{team_ties[away]}\"\n",
    "    )\n",
    "\n",
    "    # update records after the game\n",
    "    if home_score > away_score:\n",
    "        team_wins[home] += 1\n",
    "        team_losses[away] += 1\n",
    "    elif away_score > home_score:\n",
    "        team_wins[away] += 1\n",
    "        team_losses[home] += 1\n",
    "    else:\n",
    "        # tie\n",
    "        team_ties[home] += 1\n",
    "        team_ties[away] += 1\n",
    "\n",
    "# add results to dataframe\n",
    "df[\"home_team_record\"] = home_records\n",
    "df[\"away_team_record\"] = away_records\n",
    "\n",
    "\n",
    "# make individual columns for wins, losses, and ties\n",
    "df['home_wins'] = df['home_team_record'].apply(lambda x: int(x.split('-')[0]))\n",
    "df['home_losses'] = df['home_team_record'].apply(lambda x: int(x.split('-')[1]))\n",
    "df['home_ties'] = df['home_team_record'].apply(lambda x: int(x.split('-')[2]))\n",
    "df['away_wins'] = df['away_team_record'].apply(lambda x: int(x.split('-')[0]))\n",
    "df['away_losses'] = df['away_team_record'].apply(lambda x: int(x.split('-')[1]))\n",
    "df['away_ties'] = df['away_team_record'].apply(lambda x: int(x.split('-')[2]))\n",
    "\n",
    "\n",
    "# filter games that have already been recorded, no scheduled games\n",
    "df = df[df[\"datetime\"] <= \"2025-11-04\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute each team's average score per season\n",
    "team_season_avg = (\n",
    "    df.groupby([\"team_home\", \"schedule_season\"])[\"score_home\"].mean().reset_index()\n",
    ")\n",
    "team_season_avg.columns = [\"team\", \"season\", \"avg_score\"]\n",
    "\n",
    "# also include away team scoring\n",
    "team_season_avg_away = (\n",
    "    df.groupby([\"team_away\", \"schedule_season\"])[\"score_away\"].mean().reset_index()\n",
    ")\n",
    "team_season_avg_away.columns = [\"team\", \"season\", \"avg_score\"]\n",
    "\n",
    "# combine home + away scoring for a true team season average\n",
    "team_season_avg = pd.concat([team_season_avg, team_season_avg_away])\n",
    "team_season_avg = team_season_avg.groupby([\"team\", \"season\"])[\"avg_score\"].mean().reset_index()\n",
    "\n",
    "# shift averages to represent previous season\n",
    "team_season_avg[\"prev_season\"] = team_season_avg[\"season\"] + 1\n",
    "\n",
    "# prev_season avg is used in the next year's games\n",
    "team_prev = team_season_avg[[\"team\", \"prev_season\", \"avg_score\"]]\n",
    "team_prev.columns = [\"team\", \"schedule_season\", \"prev_season_avg\"]\n",
    "\n",
    "# merge into main df\n",
    "df = df.merge(team_prev, left_on=[\"team_home\", \"schedule_season\"], right_on=[\"team\", \"schedule_season\"], how=\"left\")\n",
    "df.rename(columns={\"prev_season_avg\": \"home_prev_avg\"}, inplace=True)\n",
    "df = df.drop(columns=[\"team\"])\n",
    "\n",
    "df = df.merge(team_prev, left_on=[\"team_away\", \"schedule_season\"], right_on=[\"team\", \"schedule_season\"], how=\"left\")\n",
    "df.rename(columns={\"prev_season_avg\": \"away_prev_avg\"}, inplace=True)\n",
    "df = df.drop(columns=[\"team\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating rolling avgs within each season\n",
    "\n",
    "# separate into home, away dfs\n",
    "home = df[[\"schedule_season\", \"datetime\", \"team_home\", \"score_home\", \"score_away\"]].rename(\n",
    "    columns={\"team_home\": \"team\", \"score_home\": \"points_scored\", \"score_away\": \"points_allowed\"}\n",
    ")\n",
    "\n",
    "away = df[[\"schedule_season\", \"datetime\", \"team_away\", \"score_away\", \"score_home\"]].rename(\n",
    "    columns={\"team_away\": \"team\", \"score_away\": \"points_scored\", \"score_home\": \"points_allowed\"}\n",
    ")\n",
    "\n",
    "# long df, duplicate games, sort by team, season, date\n",
    "long_df = pd.concat([home, away])\n",
    "long_df = long_df.sort_values([\"team\", \"schedule_season\", \"datetime\"]).reset_index(drop=True)\n",
    "\n",
    "groups = long_df.groupby([\"team\", \"schedule_season\"])\n",
    "\n",
    "# compute rolling averages\n",
    "long_df[\"rolling_scored\"] = groups[\"points_scored\"].transform(\n",
    "    lambda s: s.shift().expanding().mean()\n",
    ")\n",
    "\n",
    "long_df[\"rolling_allowed\"] = groups[\"points_allowed\"].transform(\n",
    "    lambda s: s.shift().expanding().mean()\n",
    ")\n",
    "\n",
    "# merge back into original df\n",
    "df = df.merge(\n",
    "    long_df[[\"team\", \"schedule_season\", \"datetime\", \"rolling_scored\", \"rolling_allowed\"]],\n",
    "    left_on=[\"team_home\", \"schedule_season\", \"datetime\"],\n",
    "    right_on=[\"team\", \"schedule_season\", \"datetime\"],\n",
    "    how=\"left\"\n",
    ").rename(\n",
    "    columns={\n",
    "        \"rolling_scored\": \"home_rolling_scored\",\n",
    "        \"rolling_allowed\": \"home_rolling_allowed\"\n",
    "    }\n",
    ").drop(columns=[\"team\"])\n",
    "\n",
    "\n",
    "df = df.merge(\n",
    "    long_df[[\"team\", \"schedule_season\", \"datetime\", \"rolling_scored\", \"rolling_allowed\"]],\n",
    "    left_on=[\"team_away\", \"schedule_season\", \"datetime\"],\n",
    "    right_on=[\"team\", \"schedule_season\", \"datetime\"],\n",
    "    how=\"left\"\n",
    ").rename(\n",
    "    columns={\n",
    "        \"rolling_scored\": \"away_rolling_scored\",\n",
    "        \"rolling_allowed\": \"away_rolling_allowed\"\n",
    "    }\n",
    ").drop(columns=[\"team\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping variables that aren't informative to our model\n",
    "df_filtered = df.drop(columns=['datetime', 'stadium_neutral', 'home_team_record', 'away_team_record',\n",
    "                       'schedule_date', 'team_favorite_id', 'team_home', 'team_away', 'schedule_week'])\n",
    "df_filtered = df_filtered.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into x and y\n",
    "X = df_filtered.drop(columns=['total_score', 'over_under_line', 'score_home', 'score_away'])\n",
    "y = df_filtered['total_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical + numeric columns\n",
    "categorical_cols = ['schedule_playoff']\n",
    "numeric_cols = [col for col in X_train.columns if col not in categorical_cols]\n",
    "\n",
    "# Column transformer to handle scaling, transformer in pipeline\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='if_binary'), categorical_cols),\n",
    "        ('num', StandardScaler(), numeric_cols)])\n",
    "\n",
    "# Build preprocess, SVR pipeline\n",
    "pip = Pipeline(steps=[('preprocess', preprocess),('svr', SVR())])\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = [\n",
    "    {\n",
    "        'svr__kernel': ['linear'],\n",
    "        'svr__C': [0.1, 1, 10, 100],\n",
    "        'svr__epsilon': [0.01, 0.1, 0.5, 1.0]\n",
    "    },\n",
    "    {\n",
    "        'svr__kernel': ['rbf'],\n",
    "        'svr__C': [0.1, 1, 10, 100],\n",
    "        'svr__gamma': ['scale', 'auto', 0.01, 0.001],\n",
    "        'svr__epsilon': [0.01, 0.1, 0.5, 1.0]\n",
    "    },\n",
    "    {\n",
    "        'svr__kernel': ['poly'],\n",
    "        'svr__C': [0.1, 1, 10, 100],\n",
    "        'svr__gamma': ['scale', 'auto'],\n",
    "        'svr__degree': [2, 3, 4],\n",
    "        'svr__epsilon': [0.01, 0.1, 0.5, 1.0]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(pip,param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit on raw X_train and y_train\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'svr__C': 10, 'svr__epsilon': 0.01, 'svr__gamma': 0.001, 'svr__kernel': 'rbf'}\n",
      "Best CV MSE: 180.348\n",
      "Best CV RMSE: 13.429\n",
      "Test R²: 0.031\n",
      "Test MSE: 208.492\n",
      "Test RMSE: 14.439\n",
      "Test MAE: 11.507\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV MSE:\", round(-grid_search.best_score_,3))\n",
    "print(\"Best CV RMSE:\", round(np.sqrt(-grid_search.best_score_),3))\n",
    "\n",
    "best_svr = grid_search.best_estimator_\n",
    "y_pred = best_svr.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "print(\"Test R²:\", round(r2_score(y_test, y_pred),3))\n",
    "print(\"Test MSE:\", round(mean_squared_error(y_test, y_pred),3))\n",
    "print(\"Test RMSE:\", round(np.sqrt(mean_squared_error(y_test, y_pred)),3))\n",
    "print(\"Test MAE:\", round(mean_absolute_error(y_test, y_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our evaluation metrics, it is clear that the SVR model does not predict well on the data. With an R² score of 0.03 and an RMSE of approximately 14.5(about 14.5 points off for every prediction), it is clear that we must use another model. We do not have enough information for SVR to accurately predict total points."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environments-4MEucMeV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
